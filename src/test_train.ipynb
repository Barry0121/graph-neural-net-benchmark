{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.args import *\n",
    "from models.dataset import *\n",
    "from models.discriminator import *\n",
    "from models.generator import *\n",
    "from models.inverter import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", UserWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_inverter=False, num_layers=4, clamp_lower=-0.1, clamp_upper=0.1, lr=1e-3, betas=1e-5, lamb=0.1, loss_func='MSE', device=choose_device()):\n",
    "    # save losses\n",
    "    iloss_lst = []\n",
    "    dloss_lst = []\n",
    "    gloss_lst = []\n",
    "\n",
    "    # get the dataset\n",
    "    train, labels = get_dataset_with_label(args.graph_type) # entire dataset as train\n",
    "    train_dataset = Graph_sequence_sampler_pytorch_nobfs(train, labels, args)\n",
    "    train_loader = get_dataloader_labels(train_dataset, args)\n",
    "    noise_dim = args.hidden_size_rnn\n",
    "    print('noise dimension is: ', noise_dim)\n",
    "\n",
    "    # initialize noise, optimizer and loss\n",
    "    netI = Inverter(input_dim=128, output_dim=args.hidden_size_rnn, hidden_dim=64)\n",
    "    netG = GraphRNN(args=args)\n",
    "    netD = NetD(stat_input_dim=128, stat_hidden_dim=64, num_stat=2)\n",
    "\n",
    "    # set up a register_hook to check parameter gradient\n",
    "    for param in netD.parameters():\n",
    "        h = param.register_hook(lambda grad: print(\"Parameter Update with gradient {:.4f}\".format(grad)))\n",
    "\n",
    "    # check model parameters\n",
    "    # for param in netD.parameters():\n",
    "    #     print(param.name, param.data, param.requires_grad)\n",
    "    # for param in netG.parameters():\n",
    "        # print(param.name, param.data, param.requires_grad)\n",
    "\n",
    "    graph2vec = get_graph2vec(args.graph_type, dim=512) # use infer() to generate new graph embedding\n",
    "    optimizerI = optim.Adam(netI.parameters(), lr=lr)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=[betas for _ in range(2)])\n",
    "    lossI = WGAN_ReconLoss(device, lamb, loss_func)\n",
    "    G_optimizer_rnn, G_optimizer_output, G_scheduler_rnn, G_scheduler_output = netG.init_optimizer(lr=0.1) # initialize optimizers\n",
    "\n",
    "\n",
    "    noise = torch.randn(args.batch_size, noise_dim).to(device)\n",
    "    one = torch.tensor(1, dtype=torch.float)\n",
    "    mone = torch.tensor(-1, dtype=torch.float)\n",
    "\n",
    "    gen_iterations = 0\n",
    "    for e in range(args.epochs):\n",
    "        # for now, treat the input as adj matrices\n",
    "        start_time = time.time()\n",
    "        e_errI, e_errD, e_errG, count_batch = 0, 0, 0, 0\n",
    "        for i, data in tqdm(enumerate(train_loader), desc=f\"Training epoch#{e+1}\", total=len(train_loader)):\n",
    "            X = data['x']\n",
    "            Y = data['y']\n",
    "            adj_mat = data['adj_mat']\n",
    "            label = data['label']\n",
    "            Y_len = data['len']\n",
    "\n",
    "            # zero grad\n",
    "            optimizerI.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "            G_optimizer_rnn.zero_grad()\n",
    "            G_optimizer_output.zero_grad()\n",
    "\n",
    "            # skip uneven batch\n",
    "            if adj_mat.size(0) != args.batch_size:\n",
    "                continue\n",
    "\n",
    "            ######################\n",
    "            # Discriminator Update\n",
    "            ######################\n",
    "            # number of iteration to train the discriminator\n",
    "            # if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            #     Diters = 20\n",
    "            # else:\n",
    "            #     Diters = 5\n",
    "            Diters = 10\n",
    "            j = 0 # counter for 1, 2, ... Diters\n",
    "\n",
    "            # enable training\n",
    "            netD.train(True)\n",
    "            netG.train(False)\n",
    "            b_errD = 0\n",
    "            while j < Diters:\n",
    "                j += 1\n",
    "                # TODO: commenting this part out for testing\n",
    "                # weight clipping: clamp parameters to a cube\n",
    "                # for p in netD.parameters():\n",
    "                #     p.data.clamp_(clamp_lower, clamp_upper)\n",
    "                # netD.zero_grad()\n",
    "\n",
    "                # train with real\n",
    "                inputs = torch.torch.empty_like(adj_mat).copy_(adj_mat)\n",
    "                input_graphs = [nx.from_numpy_matrix(i) for i in inputs.numpy()]\n",
    "                D_pred = torch.Tensor([netD(graph) for graph in input_graphs])\n",
    "                errD_real = Variable(torch.mean(D_pred), requires_grad=True)\n",
    "                errD_real.backward() # discriminator should assign 1's to true samples\n",
    "\n",
    "                # train with fake\n",
    "                # input = noise.normal_(0,1) # (batch_size, hidden_size)\n",
    "                # # insert data processing\n",
    "                # fake = netG(input, args, output_batch_size=args.batch_size)\n",
    "                # fake_tensor = torch.Tensor([netD(nx.from_numpy_matrix(f)) for f in fake.numpy()])\n",
    "                # errD_fake = Variable(torch.mean(fake_tensor), requires_grad=True)\n",
    "                # errD_fake.backward(mone) # discriminator should assign -1's to fake samples??\n",
    "\n",
    "                # # compute Wasserstein distance and update parameters\n",
    "                # errD = Variable(errD_real - errD_fake, requires_grad=False)\n",
    "\n",
    "                # print(f\"Check if the model is training: iterative value at #{j}.\")\n",
    "                # for p in netD.parameters():\n",
    "                #     print(\"Parameters gradients? :\", p.requires_grad, end='')\n",
    "                #     print(\"Parameters grad: \", p.grad)\n",
    "\n",
    "                optimizerD.step()\n",
    "                print(f\"errD_real {errD_real.item()} \")\n",
    "                # print(f\"Iterative errD {errD.item()}, errD_real {errD_real.item()}, errD_fake {errD_fake.item()}: \")\n",
    "                # b_errD += errD\n",
    "\n",
    "            # ========== Train Generator ==================\n",
    "    #         netD.train(False)\n",
    "    #         netG.train(True)\n",
    "    #         netG.clear_gradient_models()\n",
    "    #         G_optimizer_rnn.zero_grad()\n",
    "    #         G_optimizer_output.zero_grad()\n",
    "    #         # in case our last batch was the tail batch of the dataloader,\n",
    "    #         # make sure we feed a full batch of noise\n",
    "    #         noisev = Variable(noise.normal_(0,1))\n",
    "    #         fake = netG(noisev, args=args, output_batch_size=args.batch_size)\n",
    "    #         fake_tensor = torch.Tensor([netD(nx.from_numpy_matrix(f)) for f in fake.detach().numpy()])\n",
    "    #         errG = Variable(torch.mean(fake_tensor), requires_grad=True)\n",
    "    #         errG.backward(one)\n",
    "    #         G_optimizer_rnn.step()\n",
    "    #         G_optimizer_output.step()\n",
    "    #         # netG.all_steps()\n",
    "    #         gen_iterations += 1\n",
    "\n",
    "\n",
    "    #         # Winston's outline for inverter training\n",
    "    #         # 0. train graph2vec on {generator distribution, true distribution}\n",
    "    #         # 1. sample true samples x\n",
    "    #         # 2. recon_graph = netG(netI(x))\n",
    "    #         # 3. sample noise z\n",
    "    #         # 4. recon_noise = netI(netG(z))\n",
    "    #         # 5. minimize GW_dist(recon_graph - x) + lambda * MSE(recon_noise - z)\n",
    "\n",
    "    #         # ========== Train Inverter =================\n",
    "    #         # TODO: fix variables, move this into a different training loop\n",
    "    #         if train_inverter:\n",
    "    #             original_graphs = adj_mat # shape: (batch_size, padded_size, padded_size); in the case for MUTAG, padded_size is 29\n",
    "    #             graph_lst = [nx.from_numpy_matrix(am.detach().numpy()) for am in adj_mat]\n",
    "    #             # retrain graph2vec\n",
    "    #             graph2vec.fit(graph_lst)\n",
    "    #             # genearte embedding\n",
    "    #             embeddings = torch.Tensor(graph2vec.infer(graph_lst))\n",
    "    #             I_output = netI(torch.reshape(embeddings, (embeddings.shape[0], -1)))\n",
    "    #             # print(I_output.shape)\n",
    "    #             G_pred_graphs = netG(X=I_output, args=args, output_batch_size=args.batch_size)\n",
    "    #             reconst_graphs = G_pred_graphs\n",
    "    #             # noise\n",
    "    #             G_pred_noise = netG(X=noise, args=args, output_batch_size=args.batch_size) # shape: (batch_size, padded_size, padded_size)\n",
    "    #             # print(G_pred_noise.shape)\n",
    "    #             noise_graph_lst = [nx.from_numpy_matrix(am.detach().numpy()) for am in G_pred_noise]\n",
    "    #             noise_embeddings = torch.Tensor(graph2vec.infer(noise_graph_lst))\n",
    "    #             reconst_noise = netI(noise_embeddings)\n",
    "    #             # compute loss and update inverter loss\n",
    "    #             original_graphs = original_graphs.to(device)\n",
    "    #             reconst_graphs = reconst_graphs.to(device)\n",
    "    #             noise = noise.to(device)\n",
    "    #             reconst_noise = reconst_noise.to(device)\n",
    "    #             iloss = lossI(original_graphs, reconst_graphs, noise, reconst_noise)\n",
    "    #             iloss.backward()\n",
    "    #             optimizerI.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #         # # compute mean error across all batches\n",
    "    #         e_errD += b_errD.item()\n",
    "    #         e_errG += errG.item()\n",
    "    #         if train_inverter:\n",
    "    #             e_errI += iloss.item()\n",
    "    #         count_batch += 1\n",
    "\n",
    "    #     # Print out training information per epoch.\n",
    "    #     if train_inverter:\n",
    "    #         if (e+1) % 1 == 0:\n",
    "    #             elapsed_time = time.time() - start_time\n",
    "    #             print('Elapsed time [{:.4f}], Iteration [{}/{}], I Loss: {:.4f}, D Loss: {:.4f}, G Loss {:.4f}'.format(\n",
    "    #                 elapsed_time, e+1, args.epochs, e_errI/count_batch, e_errD/count_batch, e_errG/count_batch))\n",
    "    #     else:\n",
    "    #         if (e+1) % 1 == 0:\n",
    "    #             elapsed_time = time.time() - start_time\n",
    "    #             print('Elapsed time [{:.4f}], Iteration [{}/{}], D Loss: {:.4f}, G Loss {:.4f}'.format(\n",
    "    #                 elapsed_time, e+1, args.epochs, e_errD/count_batch, e_errG/count_batch))\n",
    "\n",
    "\n",
    "    #     # append training loss across\n",
    "    #     if train_inverter:\n",
    "    #         iloss_lst.append(e_errI/count_batch)\n",
    "    #     dloss_lst.append(e_errD/count_batch)\n",
    "    #     gloss_lst.append(e_errG/count_batch)\n",
    "\n",
    "    # # save loss\n",
    "    # if train_inverter:\n",
    "    #     np.savetxt('./cache/graphrnn/loss_results/inverter_loss.txt', iloss_lst, delimiter=',')\n",
    "    # np.savetxt('./cache/graphrnn/loss_results/discriminator_loss.txt', dloss_lst, delimiter=',')\n",
    "    # np.savetxt('./cache/graphrnn/loss_results/generator_loss.txt', gloss_lst, delimiter=',')\n",
    "\n",
    "    # # save models\n",
    "    # Gpath = './cache/graphrnn/saved_model/generator.pth'\n",
    "    # Dpath = './cache/graphrnn/saved_model/discriminator.pth'\n",
    "    # torch.save(netG.state_dict(), Gpath)\n",
    "    # torch.save(netD.state_dict(), Dpath)\n",
    "    # if train_inverter:\n",
    "    #     Ipath = './cache/graphrnn/saved_model/inverter.pth'\n",
    "    #     torch.save(netI.state_dict(), Ipath)\n",
    "\n",
    "    print(\"====End of Training====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, labels = get_dataset_with_label(args.graph_type) # entire dataset as train\n",
    "# train_dataset = Graph_sequence_sampler_pytorch(train, labels, args)\n",
    "# train_loader = get_dataloader_labels(train_dataset, args)\n",
    "# e = 0\n",
    "# for i, data in tqdm(enumerate(train_loader), desc=f\"Training epoch#{e+1}\", total=len(train_loader)):\n",
    "#     X = data['x']\n",
    "#     Y = data['y']\n",
    "\n",
    "#     print(X.size(), Y.size())\n",
    "#     print(X)\n",
    "#     print('-'*50)\n",
    "#     print(Y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise dimension is:  128\n",
      "======Generating Embedding======\n",
      "======Embedding Created (used 1.0396974086761475 sec)======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:   3%|▎         | 1/35 [00:03<01:57,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.000636954908259213 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:   6%|▌         | 2/35 [00:06<01:53,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0011278112651780248 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:   9%|▊         | 3/35 [00:10<01:51,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0016568265855312347 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:  11%|█▏        | 4/35 [00:13<01:47,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real 0.0006201446522027254 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:  14%|█▍        | 5/35 [00:17<01:46,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.001002114382572472 \n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "Parameters gradients? : TrueParameters grad:  None\n",
      "errD_real -0.0030824297573417425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch#1:  14%|█▍        | 5/35 [00:18<01:51,  3.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(args\u001b[39m=\u001b[39;49margs)\n",
      "Cell \u001b[0;32mIn[16], line 88\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, train_inverter, num_layers, clamp_lower, clamp_upper, lr, betas, lamb, loss_func, device)\u001b[0m\n\u001b[1;32m     86\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtorch\u001b[39m.\u001b[39mempty_like(adj_mat)\u001b[39m.\u001b[39mcopy_(adj_mat)\n\u001b[1;32m     87\u001b[0m input_graphs \u001b[39m=\u001b[39m [nx\u001b[39m.\u001b[39mfrom_numpy_matrix(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mnumpy()]\n\u001b[0;32m---> 88\u001b[0m D_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([netD(graph) \u001b[39mfor\u001b[39;00m graph \u001b[39min\u001b[39;00m input_graphs])\n\u001b[1;32m     89\u001b[0m errD_real \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mmean(D_pred), requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m errD_real\u001b[39m.\u001b[39mbackward() \u001b[39m# discriminator should assign 1's to true samples\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtorch\u001b[39m.\u001b[39mempty_like(adj_mat)\u001b[39m.\u001b[39mcopy_(adj_mat)\n\u001b[1;32m     87\u001b[0m input_graphs \u001b[39m=\u001b[39m [nx\u001b[39m.\u001b[39mfrom_numpy_matrix(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mnumpy()]\n\u001b[0;32m---> 88\u001b[0m D_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([netD(graph) \u001b[39mfor\u001b[39;00m graph \u001b[39min\u001b[39;00m input_graphs])\n\u001b[1;32m     89\u001b[0m errD_real \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mmean(D_pred), requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m errD_real\u001b[39m.\u001b[39mbackward() \u001b[39m# discriminator should assign 1's to true samples\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/DSC180B-PlayGround/graph-neural-net-benchmark/src/models/discriminator.py:68\u001b[0m, in \u001b[0;36mNetD.forward\u001b[0;34m(self, G)\u001b[0m\n\u001b[1;32m     64\u001b[0m degree_hist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(degree_hist)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n\u001b[1;32m     65\u001b[0m degree_hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstat_NNs[\u001b[39m0\u001b[39m](degree_hist)\n\u001b[1;32m     67\u001b[0m clustering_coefs, _ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhistogram(\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mlist\u001b[39m(nx\u001b[39m.\u001b[39;49mclustering(G)\u001b[39m.\u001b[39mvalues()),\n\u001b[1;32m     69\u001b[0m     bins\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstat_input_dim, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m(\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m), density\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m clustering_coefs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(clustering_coefs)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n\u001b[1;32m     71\u001b[0m clustering_coefs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstat_NNs[\u001b[39m1\u001b[39m](clustering_coefs)\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/site-packages/networkx/algorithms/cluster.py:370\u001b[0m, in \u001b[0;36mclustering\u001b[0;34m(G, nodes, weight)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m         td_iter \u001b[39m=\u001b[39m _triangles_and_degree_iter(G, nodes)\n\u001b[0;32m--> 370\u001b[0m         clusterc \u001b[39m=\u001b[39m {v: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t \u001b[39m/\u001b[39m (d \u001b[39m*\u001b[39m (d \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m v, d, t, _ \u001b[39min\u001b[39;00m td_iter}\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m nodes \u001b[39min\u001b[39;00m G:\n\u001b[1;32m    372\u001b[0m     \u001b[39m# Return the value of the sole entry in the dictionary.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m clusterc[nodes]\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/site-packages/networkx/algorithms/cluster.py:370\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m         td_iter \u001b[39m=\u001b[39m _triangles_and_degree_iter(G, nodes)\n\u001b[0;32m--> 370\u001b[0m         clusterc \u001b[39m=\u001b[39m {v: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t \u001b[39m/\u001b[39m (d \u001b[39m*\u001b[39m (d \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m v, d, t, _ \u001b[39min\u001b[39;00m td_iter}\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m nodes \u001b[39min\u001b[39;00m G:\n\u001b[1;32m    372\u001b[0m     \u001b[39m# Return the value of the sole entry in the dictionary.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m clusterc[nodes]\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/site-packages/networkx/algorithms/cluster.py:78\u001b[0m, in \u001b[0;36m_triangles_and_degree_iter\u001b[0;34m(G, nodes)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m v, v_nbrs \u001b[39min\u001b[39;00m nodes_nbrs:\n\u001b[1;32m     77\u001b[0m     vs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(v_nbrs) \u001b[39m-\u001b[39m {v}\n\u001b[0;32m---> 78\u001b[0m     gen_degree \u001b[39m=\u001b[39m Counter(\u001b[39mlen\u001b[39;49m(vs \u001b[39m&\u001b[39;49m (\u001b[39mset\u001b[39;49m(G[w]) \u001b[39m-\u001b[39;49m {w})) \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m vs)\n\u001b[1;32m     79\u001b[0m     ntriangles \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(k \u001b[39m*\u001b[39m val \u001b[39mfor\u001b[39;00m k, val \u001b[39min\u001b[39;00m gen_degree\u001b[39m.\u001b[39mitems())\n\u001b[1;32m     80\u001b[0m     \u001b[39myield\u001b[39;00m (v, \u001b[39mlen\u001b[39m(vs), ntriangles, gen_degree)\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/collections/__init__.py:593\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[39mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39mof elements to their counts.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \n\u001b[1;32m    591\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 593\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(iterable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.conda/envs/dev180/lib/python3.9/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39m# The regular dict.update() operation makes no sense here because the\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39m# replace behavior results in the some of original untouched counts\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[39m# being mixed-in with all of the other counts for a mismash that\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m# doesn't have a straight-forward interpretation in most counting\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39m# contexts.  Instead, we implement straight-addition.  Both the inputs\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m# and outputs are allowed to contain zero and negative counts.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mif\u001b[39;00m iterable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(iterable, _collections_abc\u001b[39m.\u001b[39;49mMapping):\n\u001b[1;32m    671\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m    672\u001b[0m             self_get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args=args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a3a2ecaabf27beca2883a9dba2b6875b07db1b2c8ad2f920ab70c4c2e7a16bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
