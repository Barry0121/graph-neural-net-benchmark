{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import numpy as np\n",
    "import time as tm\n",
    "\n",
    "from generator_utils import *\n",
    "# from args import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_plain(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, has_input=True, has_output=False, output_size=None):\n",
    "        super(GRU_plain, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.has_input = has_input\n",
    "        self.has_output = has_output\n",
    "\n",
    "        if has_input:\n",
    "            self.input = nn.Linear(input_size, embedding_size)\n",
    "            self.rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        if has_output:\n",
    "            self.output = nn.Sequential(\n",
    "                nn.Linear(hidden_size, embedding_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_size, output_size)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # initialize\n",
    "        self.hidden = None  # need initialize before forward run\n",
    "\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.25)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param,gain=nn.init.calculate_gain('sigmoid'))\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(choose_device())\n",
    "\n",
    "    def forward(self, input_raw, pack=False, input_len=None):\n",
    "        if self.has_input:\n",
    "            input = self.input(input_raw)\n",
    "            input = self.relu(input)\n",
    "        else:\n",
    "            input = input_raw\n",
    "        if pack:\n",
    "            input = pack_padded_sequence(input, input_len, batch_first=True)\n",
    "        output_raw, self.hidden = self.rnn(input, self.hidden)\n",
    "        if pack:\n",
    "            output_raw = pad_packed_sequence(output_raw, batch_first=True)[0]\n",
    "        if self.has_output:\n",
    "            output_raw = self.output(output_raw)\n",
    "        # return hidden state at each time step\n",
    "        return output_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRNN(nn.Module):\n",
    "    def __init__(self, args, device=choose_device()) -> None:\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.rnn = GRU_plain(input_size=self.args.max_prev_node, embedding_size=self.args.embedding_size_rnn,\n",
    "                        hidden_size=self.args.hidden_size_rnn, num_layers=self.args.num_layers, has_input=True,\n",
    "                        has_output=True, output_size=self.args.hidden_size_rnn_output).to(self.device)\n",
    "        self.output = GRU_plain(input_size=1, embedding_size=self.args.embedding_size_rnn_output,\n",
    "                            hidden_size=self.args.hidden_size_rnn_output, num_layers=self.args.num_layers, has_input=True,\n",
    "                            has_output=True, output_size=1).to(self.device)\n",
    "\n",
    "        # load data state\n",
    "        if args.load:\n",
    "            fname = args.model_save_path + args.fname + 'lstm_' + str(args.load_epoch) + '.dat'\n",
    "            self.rnn.load_state_dict(torch.load(fname))\n",
    "            fname = args.model_save_path + args.fname + 'output_' + str(args.load_epoch) + '.dat'\n",
    "            self.output.load_state_dict(torch.load(fname))\n",
    "\n",
    "            args.lr = 0.00001\n",
    "            epoch = args.load_epoch\n",
    "            print('model loaded!, lr: {}'.format(args.lr))\n",
    "        else:\n",
    "            epoch = 1\n",
    "\n",
    "    # ====Call these in training loop====\n",
    "    def init_optimizer(self, lr):\n",
    "        \"\"\"Initialize optimizers and schedular for both RNNs\"\"\"\n",
    "        self.optimizer_rnn = optim.Adam(list(self.rnn.parameters()), lr=lr)\n",
    "        self.optimizer_output = optim.Adam(list(self.output.parameters()), lr=lr)\n",
    "        self.scheduler_rnn = MultiStepLR(self.optimizer_rnn, milestones=self.args.milestones)\n",
    "        self.scheduler_output = MultiStepLR(self.optimizer_output, milestones=self.args.milestones)\n",
    "        return self.optimizer_rnn, self.optimizer_output, self.scheduler_rnn, self.scheduler_output\n",
    "\n",
    "    def clear_gradient_models(self):\n",
    "        self.rnn.zero_grad()\n",
    "        self.output.zero_grad()\n",
    "\n",
    "    def train(self, flag):\n",
    "        if flag:\n",
    "            self.rnn.train(True)\n",
    "            self.output.train(True)\n",
    "        else:\n",
    "            self.rnn.train(False)\n",
    "            self.output.train(False)\n",
    "\n",
    "    def clear_gradient_opts(self):\n",
    "        self.optimizer_rnn.zero_grad()\n",
    "        self.optimizer_output.zero_grad()\n",
    "\n",
    "    def all_steps(self):\n",
    "        self.optimizer_rnn.step()\n",
    "        self.optimizer_output.step()\n",
    "        self.scheduler_rnn.step()\n",
    "        self.scheduler_output.step()\n",
    "\n",
    "    # ======================================\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: noise/latent vector\n",
    "        args: arguments dictionary\n",
    "        test_batch_size: number of graphs you want to generate\n",
    "        \"\"\"\n",
    "        # provide a option to change number of graphs generated\n",
    "        output_batch_size = self.args.test_batch_size\n",
    "        input_hidden = torch.stack(self.rnn.num_layers*[X]).to(self.device)\n",
    "        self.rnn.hidden = input_hidden # expected shape: (num_layer, batch_size, hidden_size)\n",
    "\n",
    "        # TODO: change this part to noise vector might need resizing\n",
    "        y_pred_long = Variable(torch.zeros(output_batch_size, self.args.max_num_node, self.args.max_prev_node)).to(self.device) # discrete prediction\n",
    "        # x_step = X.to(self.device) # shape:(batch_size, 1, self.args.max_prev_node)\n",
    "        x_step = Variable(torch.ones(output_batch_size, 1, self.args.max_prev_node)).to(self.device)\n",
    "\n",
    "        # iterative graph generation\n",
    "        for i in range(self.args.max_num_node):\n",
    "            # for each node\n",
    "            # 1. we use rnn to create new node embedding\n",
    "            # 2. we use output to create new edges\n",
    "\n",
    "            # (1)\n",
    "            h = self.rnn(x_step)\n",
    "            hidden_null = Variable(torch.zeros(self.args.num_layers - 1, h.size(0), h.size(2))).to(self.device)\n",
    "            x_step = Variable(torch.zeros(output_batch_size, 1, self.args.max_prev_node)).to(self.device)\n",
    "            output_x_step = Variable(torch.ones(output_batch_size, 1, 1)).to(self.device)\n",
    "            # (2)\n",
    "            self.output.hidden = torch.cat((h.permute(1,0,2), hidden_null), dim=0).to(self.device)\n",
    "            for j in range(min(self.args.max_prev_node,i+1)):\n",
    "                output_y_pred_step = self.output(output_x_step)\n",
    "                # print(output_y_pred_step.requires_grad)\n",
    "                output_x_step = sample_sigmoid(output_y_pred_step, sample=True, sample_time=1, device=self.device)\n",
    "                x_step[:,:,j:j+1] = output_x_step\n",
    "                # self.output.hidden = Variable(self.output.hidden.data).to(self.device)\n",
    "            y_pred_long[:, i:i + 1, :] = x_step\n",
    "            # self.rnn.hidden = Variable(self.rnn.hidden.data).to(self.device)\n",
    "        y_pred_long_data = y_pred_long.data.long()\n",
    "\n",
    "        init_adj_pred = decode_adj(y_pred_long_data[0].cpu())\n",
    "        adj_pred_list = torch.zeros((output_batch_size, init_adj_pred.size(0), init_adj_pred.size(1)))\n",
    "        for i in range(output_batch_size):\n",
    "            # adj_pred = decode_adj(y_pred_long_data[i].cpu().numpy())\n",
    "            # adj_pred_list = np.append(adj_pred_list, adj_pred)\n",
    "            # adj_pred_list.append(adj_pred)\n",
    "            adj_pred_list[i, :, :] = decode_adj(y_pred_long_data[i].cpu())\n",
    "\n",
    "        # return torch.Tensor(np.array(adj_pred_list))\n",
    "        return adj_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a3a2ecaabf27beca2883a9dba2b6875b07db1b2c8ad2f920ab70c4c2e7a16bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
