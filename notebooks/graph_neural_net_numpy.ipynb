{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference website for overview of GCN: [LINK](http://tkipf.github.io/graph-convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: NumPy Example of GCN on Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import fractional_matrix_power\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "#Initialize the graph\n",
    "G = nx.Graph(name='G')\n",
    "\n",
    "#Create nodes\n",
    "#In this example, the graph will consist of 6 nodes.\n",
    "#Each node is assigned node feature which corresponds to the node name\n",
    "for i in range(6):\n",
    "    G.add_node(i, name=i)\n",
    "\n",
    "\n",
    "#Define the edges and the edges to the graph\n",
    "edges = [(0,1),(0,2),(1,2),(0,3),(3,4),(3,5),(4,5)]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "#See graph info\n",
    "print('Graph Info:\\n', nx.info(G))\n",
    "\n",
    "#Inspect the node features\n",
    "print('\\nGraph Nodes: ', G.nodes.data())\n",
    "\n",
    "#Plot the graph\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Adjacency Matrix (A) and Node Features Matrix (X) as numpy array\n",
    "A = np.array(nx.attr_matrix(G, node_attr='name')[0])\n",
    "X = np.array(nx.attr_matrix(G, node_attr='name')[1])\n",
    "X = np.expand_dims(X,axis=1)\n",
    "\n",
    "print('Shape of A: ', A.shape)\n",
    "print('\\nShape of X: ', X.shape)\n",
    "print('\\nAdjacency Matrix (A):\\n', A)\n",
    "print('\\nNode Features Matrix (X):\\n', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product Adjacency Matrix (A) and Node Features (X)\n",
    "AX = np.dot(A,X)\n",
    "print(\"Dot product of A and X (AX):\\n\", AX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dot product of Adjacency Matrix and Node Features Matrix represents the sum of neighboring node features.\n",
    "#### But, if we think about it more, we will realize that while AX sums up the adjacent node features, it does not take into account the features of the node itself.\n",
    "* So we have to insert some self loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Self Loops\n",
    "G_self_loops = G.copy()\n",
    "\n",
    "self_loops = []\n",
    "for i in range(G.number_of_nodes()):\n",
    "    self_loops.append((i,i))\n",
    "\n",
    "G_self_loops.add_edges_from(self_loops)\n",
    "\n",
    "# Check the edges of G_self_loops after adding the self loops\n",
    "print('Edges of G with self-loops:\\n', G_self_loops.edges)\n",
    "\n",
    "# Get the Adjacency Matrix (A) and Node Features Matrix (X) of added self-lopps graph\n",
    "A_hat = np.array(nx.attr_matrix(G_self_loops, node_attr='name')[0])\n",
    "print('Adjacency Matrix of added self-loops G (A_hat):\\n', A_hat)\n",
    "\n",
    "# Calculate the dot product of A_hat and X (AX)\n",
    "AX = np.dot(A_hat, X)\n",
    "print('AX:\\n', AX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by finding the dot product with degree matrix\n",
    "#Get the Degree Matrix of the added self-loops graph\n",
    "Deg_Mat = G_self_loops.degree()\n",
    "print('Degree Matrix of added self-loops G (D): ', Deg_Mat)\n",
    "\n",
    "#Convert the Degree Matrix to a N x N matrix where N is the number of nodes\n",
    "D = np.diag([deg for (n,deg) in list(Deg_Mat)])\n",
    "print('Degree Matrix of added self-loops G as numpy array (D):\\n', D)\n",
    "\n",
    "#Find the inverse of Degree Matrix (D)\n",
    "D_inv = np.linalg.inv(D)\n",
    "print('Inverse of D:\\n', D_inv)\n",
    "\n",
    "#Dot product of D and AX for normalization\n",
    "DAX = np.dot(D_inv,AX)\n",
    "print('DAX:\\n', DAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization from the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetrically-normalization\n",
    "D_half_norm = fractional_matrix_power(D, -0.5)\n",
    "DADX = D_half_norm.dot(A_hat).dot(D_half_norm).dot(X)\n",
    "print('DADX:\\n', DADX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Weights and Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the weights\n",
    "np.random.seed(77777)\n",
    "n_h = 4 #number of neurons in the hidden layer\n",
    "n_y = 2 #number of neurons in the output layer\n",
    "W0 = np.random.randn(X.shape[1],n_h) * 0.01\n",
    "W1 = np.random.randn(n_h,n_y) * 0.01\n",
    "\n",
    "#Implement ReLu as activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "#Build GCN layer\n",
    "#In this function, we implement numpy to simplify\n",
    "def gcn(A,H,W):\n",
    "    I = np.identity(A.shape[0]) #create Identity Matrix of A\n",
    "    A_hat = A + I # add self-loop to A\n",
    "    D = np.diag(np.sum(A_hat, axis=0)) #create Degree Matrix of A\n",
    "    D_half_norm = fractional_matrix_power(D, -0.5) #calculate D to the power of -0.5\n",
    "    eq = D_half_norm.dot(A_hat).dot(D_half_norm).dot(H).dot(W)\n",
    "    return relu(eq)\n",
    "\n",
    "\n",
    "#Do forward propagation\n",
    "H1 = gcn(A,X,W0) # Layer one \n",
    "H2 = gcn(A,H1,W1) # Layer two\n",
    "print('Features Representation from GCN output:\\n', H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_features(H2):\n",
    "    #Plot the features representation\n",
    "    x = H2[:,0]\n",
    "    y = H2[:,1]\n",
    "\n",
    "    size = 1000\n",
    "\n",
    "    plt.scatter(x,y,size)\n",
    "    plt.xlim([np.min(x)*0.9, np.max(x)*1.1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel('Feature Representation Dimension 0')\n",
    "    plt.ylabel('Feature Representation Dimension 1')\n",
    "    plt.title('Feature Representation')\n",
    "\n",
    "    for i,row in enumerate(H2):\n",
    "        str = \"{}\".format(i)\n",
    "        plt.annotate(str, (row[0],row[1]),fontsize=18, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_features(H2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ee9abc2f8ed4c2bec59380a88532f6c4409e3142704504d9be0d180fda6aa0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
