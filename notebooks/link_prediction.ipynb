{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.12.0+.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp39-cp39-linux_x86_64.whl size=306068 sha256=d4d71ad69d3d8a0e26de9499902a493f575e1177bdfc9ce0ffe96af9818bb952\n",
      "  Stored in directory: /home/zex001/.cache/pip/wheels/0f/60/0a/78e62f3c2b8055590441b1cb389eb274e3740d8d7462c7abd8\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.9\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.12.0+.html\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 13.7 MB/s eta 0:00:01MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from torch-sparse) (1.7.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from scipy->torch-sparse) (1.19.5)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp39-cp39-linux_x86_64.whl size=612386 sha256=79f115ef97644ec0b5ef3a04d7d1ab36051c57d4401d04118675aa8648534fc1\n",
      "  Stored in directory: /home/zex001/.cache/pip/wheels/bc/9e/f5/f493101401d551fa7223cbdfc220c26772c697c0f5ebeccca8\n",
      "Successfully built torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.15\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
      "\u001b[K     |████████████████████████████████| 467 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (4.61.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (1.7.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (2.26.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (0.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (2.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689843 sha256=3e153c515c908d4ebd6badb1f3dad5eb5a64aaaaa60510386281e3c709f98cf4\n",
      "  Stored in directory: /home/zex001/.cache/pip/wheels/d0/1c/ed/a1eeba09902954614d226f99a0b68d203a76155bb3920659f2\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.1.0.post1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_209/3694182389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+${CUDA}.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch-geometric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgnn\u001b[0m \u001b[0;31m# import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlanetoid\u001b[0m \u001b[0;31m# import dataset CORA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard pacakges \n",
    "import torch \n",
    "from torch import nn, utils\n",
    "import networkx as nx \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Pytroch Geometric \n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+${CUDA}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+${CUDA}.html\n",
    "!pip install torch-geometric\n",
    "from torch_geometric import utils as gutils\n",
    "from torch_geometric import nn as gnn # import layers \n",
    "from torch_geometric.datasets import Planetoid # import dataset CORA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Model Training/Evaluation Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_utils: \n",
    "    def __init__(self, dataset, epochs): \n",
    "        # store the data\n",
    "        # TODO: Change the raw dataset to a dataloader object from PyTorch\n",
    "        self.dataset = dataset  \n",
    "        if 'x' in self.dataset:\n",
    "            self.node_features = self.dataset.x\n",
    "        else: \n",
    "            print(\"Input Dataset has no node features.\")\n",
    "        self.edge_index = self.dataset.edge_index\n",
    "        self.node_labels = self.dataset.y \n",
    "\n",
    "        # print some dataset statistics \n",
    "        print(f'Number of nodes: {dataset.num_nodes}')\n",
    "        print(f'Number of edges: {dataset.num_edges}')\n",
    "        print(f'Average node degree: {dataset.num_edges / dataset.num_nodes:.2f}')\n",
    "        if 'train_mask' in dataset:\n",
    "            print(f'Number of training nodes: {dataset.train_mask.sum()}')\n",
    "            print(f'Training node label rate: {int(dataset.train_mask.sum()) / dataset.num_nodes:.2f}')\n",
    "        print(f'Has isolated nodes: {dataset.has_isolated_nodes()}')\n",
    "        print(f'Has self-loops: {dataset.has_self_loops()}')\n",
    "        print(f'Is undirected: {dataset.is_undirected()}')\n",
    "\n",
    "\n",
    "        # training/validation split\n",
    "\n",
    "        # Hyperparameters \n",
    "        self.epochs = epochs\n",
    "        self.train_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.test_loss = 0 \n",
    "        self.validation_acc = []\n",
    "        self.test_acc = 0\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Utility functions: \n",
    "    - load dataset \n",
    "    - loss function \n",
    "    - optimizer \n",
    "    - train/validation\n",
    "    - test\n",
    "    \"\"\"\n",
    "\n",
    "    def initialize_training(self): \n",
    "        \"\"\" Initialize Training Utilities \"\"\"\n",
    "        pass \n",
    "\n",
    "    def train_step(self): \n",
    "        \"\"\" One Training Step \"\"\"\n",
    "        pass\n",
    "\n",
    "    def test(self): \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom GCN Layer for weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConvCustom(nn.Module):\n",
    "    def __init__(self, \n",
    "                edge_index,\n",
    "                # node_batch,\n",
    "                input_dim, \n",
    "                output_dim, \n",
    "                random_init=True, \n",
    "                with_bias=False,\n",
    "                device='cuda:0' if torch.cuda.is_available() else 'mps'):\n",
    "        super(GCNConvCustom, self).__init__()\n",
    "        # print(\"layer initialized\")\n",
    "\n",
    "        \"\"\"Metadata\"\"\"\n",
    "        self.device = device # initialize the hosting device\n",
    "        self.with_bias = with_bias\n",
    "\n",
    "        \"\"\"Calculate Matrices\"\"\"\n",
    "        # the adjacency matrix with self-loop \n",
    "        \n",
    "        self.A = gutils.to_dense_adj(edge_index).to(self.device)[0]\n",
    "        self.A_self = self.A + torch.diag(torch.ones(self.A.shape[0], device=self.device))\n",
    "        # print(\"Adj Matrix with self loop: \", self.A)\n",
    "        \n",
    "        # calculate the degree matrix with A after added self loop\n",
    "        self.D = torch.sum(self.A_self, dim=0).to(self.device)  # Note: these are the elements along the diagonal of D\n",
    "        # print(\"Degree Matrix: \", self.D)\n",
    "\n",
    "        # for diagonal matrix, raising it to any power is the same as raising its diagonal elements to that power\n",
    "        # we can just apply the -1/2 power to all element of this degree matrix \n",
    "        # self.D_half_norm = torch.reciprocal(torch.sqrt(self.D)) \n",
    "        # self.D_half_norm = torch.from_numpy(fractional_matrix_power(self.D, -0.5)).to(self.device)\n",
    "        self.D_half_norm = torch.diag(torch.pow(self.D, -0.5))\n",
    "        # print(\"Normalization Matrix: \", self.D_half_norm)\n",
    "\n",
    "        # normalized adjacency matrix\n",
    "        # self.A_s = torch.mm(torch.mm(self.D_half_norm, self.A), self.D_half_norm) \n",
    "        self.A_s = self.D_half_norm @ self.A_self @ self.D_half_norm\n",
    "        # print(self.A_s.shape)\n",
    "        \n",
    "        # initialize learnable weights\n",
    "        # the weight should have shape of (N , F) where N is the size of the input, and F is the output dimension\n",
    "        self.W, self.b = None, None\n",
    "        if random_init: \n",
    "            self.W = torch.nn.Parameter(\n",
    "                data=(torch.rand(input_dim, output_dim, device=self.device) * 0.01),  # times it by 0.001 to make the weight smaller\n",
    "                requires_grad=True\n",
    "            )\n",
    "            # create trainable a bias term for the layer\n",
    "            self.b = torch.nn.Parameter(\n",
    "                data=(torch.rand(output_dim, 1, device=self.device) * 0.01),\n",
    "                requires_grad=True\n",
    "            )\n",
    "        else: \n",
    "            self.W = torch.nn.Parameter(\n",
    "                data=torch.ones(input_dim, output_dim, device=self.device), \n",
    "                requires_grad=True\n",
    "            )\n",
    "            self.b = torch.nn.Parameter(\n",
    "                data=torch.ones(output_dim, 1, device=self.device), \n",
    "                requires_grad=True\n",
    "            )\n",
    "\n",
    "    def forward(self, H):\n",
    "        if self.with_bias: \n",
    "            return self.A_s @ H @ self.W + self.b.T\n",
    "        else: \n",
    "            return self.A_s @ H @ self.W\n",
    "\n",
    "    def get_adj_matrix(self, with_self=False):\n",
    "        if with_self: \n",
    "            return self.A_self \n",
    "        return self.A\n",
    "    \n",
    "    def get_normalized_adj_matrix(self): \n",
    "        return self.A_s\n",
    "\n",
    "    def get_degree_matrix(self, normalization=False): \n",
    "        if normalization: \n",
    "            return self.D_half_norm\n",
    "        return self.D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporally data reading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Planetoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_209/2988669951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_cora_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load the cora dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_209/2988669951.py\u001b[0m in \u001b[0;36mloader_cora_torch\u001b[0;34m(filepath, transform, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloader_cora_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../data/raw/Planetoid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Return the CORA dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cora'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'public'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return a class of datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print some dataset statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Planetoid' is not defined"
     ]
    }
   ],
   "source": [
    "def loader_cora_torch(filepath=\"../data/raw/Planetoid\", transform=None, batch_size=1, shuffle=False):\n",
    "    \"\"\"Return the CORA dataset\"\"\"\n",
    "    dataset = Planetoid(root=filepath, name='Cora', split='public', num_train_per_class=20, num_val=500, num_test=1000, transform=transform) # return a class of datasets\n",
    "    data = dataset[0]\n",
    "    # print some dataset statistics \n",
    "    print(f'Loads Cora dataset, at root location: {filepath}')\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "    print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "    return data.edge_index, data.x, data.y\n",
    "\n",
    "\n",
    "edge_index, node_features, labels = loader_cora_torch(shuffle=True) # load the cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[45.2056, 45.2056, 45.2056, 45.2056, 45.2056],\n",
       "        [33.8967, 33.8967, 33.8967, 33.8967, 33.8967],\n",
       "        [46.2932, 46.2932, 46.2932, 46.2932, 46.2932],\n",
       "        ...,\n",
       "        [10.0000, 10.0000, 10.0000, 10.0000, 10.0000],\n",
       "        [47.9280, 47.9280, 47.9280, 47.9280, 47.9280],\n",
       "        [50.5896, 50.5896, 50.5896, 50.5896, 50.5896]], device='mps:0',\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test custom GCN Layer \n",
    "layer1 = GCNConvCustom(edge_index=edge_index, input_dim=node_features.shape[0], output_dim=10, random_init=False)\n",
    "output1 = layer1(layer1.get_adj_matrix())\n",
    "layer2 = GCNConvCustom(edge_index=edge_index, input_dim=10, output_dim=5, random_init=False)\n",
    "layer2(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of 2 GCN Convolution Layers Auto-encoder\n",
    "reference: \n",
    "* https://towardsdatascience.com/tutorial-on-variational-graph-auto-encoders-da9333281129 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_AE(nn.Module): \n",
    "    \"\"\"\n",
    "    Graph Convolutional Auto-Encoder\n",
    "\n",
    "    GCN layer implementation from: \n",
    "        https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                edge_index, \n",
    "                input_size, \n",
    "                hidden_size_1,\n",
    "                hidden_size_2,\n",
    "                encoding_size,\n",
    "                output_size, \n",
    "                device= 'cuda:0' if torch.cuda.is_available() else 'mps'): \n",
    "        super().__init__()\n",
    "        # meta information\n",
    "        self.device = device\n",
    "        self.edge_index = edge_index # same as edge list, replace adjacency matrix \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.encoding_size = encoding_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # training utilities \n",
    "        self.criterion = None \n",
    "        self.optimizer = None \n",
    "        \n",
    "        # layers \n",
    "        self.GCN_1 = GCNConvCustom(edge_index=self.edge_index, in_channels=self.input_size, out_channels=self.hidden_size_1, random_init=False, device=self.device) \n",
    "        self.GCN_2 = GCNConvCustom(edge_index=self.edge_index, in_channels=self.hidden_size_1, out_channels=self.hidden_size_2, random_init=False, device=self.device)\n",
    "        self.FC = nn.Linear(in_features=self.hidden_size_2, out_features=self.encoding_size)\n",
    "\n",
    "        # activations \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encoder(self, X): \n",
    "        X_hat = self.GCN_1(X) # first layer: lower dimension feature matrix\n",
    "        X_hat = self.relu(X_hat) \n",
    "        H = self.GCN_2(X_hat) # second layer: mean matrix\n",
    "        H = self.relu(H)\n",
    "        Z = self.FC(H)\n",
    "        Z = self.relu(Z) # this activation may or may not be here, doesn't make a difference  \n",
    "        return Z\n",
    "\n",
    "    def decoder(self, Z): \n",
    "        Y_inner = torch.mm(Z.T, Z) # calculate inner product of matrix \n",
    "        Y_inner = Y_inner.reshape((-1)) # flatten the tensor \n",
    "        Y = self.sigmoid(Y_inner) # apply activation \n",
    "        return Y\n",
    "\n",
    "    def forward(self, X): \n",
    "        Z = self.encoder(X)\n",
    "        output = self.decoder(Z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of 2 GCN Convolution Layers Variational Auto-encoder \n",
    "references: \n",
    "* https://towardsdatascience.com/tutorial-on-variational-graph-auto-encoders-da9333281129 \n",
    "* https://github.com/tkipf/gae/blob/0ebbe9b9a8f496eb12deb9aa6a62e7016b5a5ac3/gae/model.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_VAE(nn.Module): \n",
    "    \"\"\"\n",
    "    Graph Variational Convolutional Auto-Encoder\n",
    "\n",
    "    GCN layer implementation from: \n",
    "        https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                edge_index, \n",
    "                input_size, \n",
    "                hidden_size,\n",
    "                encoding_size,\n",
    "                output_size, \n",
    "                device= 'cuda:0' if torch.cuda.is_available() else 'mps'): \n",
    "        super().__init__()\n",
    "        # meta information\n",
    "        self.device = device\n",
    "        self.edge_index = edge_index # same as edge list, replace adjacency matrix \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoding_size = encoding_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # layers \n",
    "        self.GCN_1 = gnn.GCNConv(in_channels=self.input_size, out_channels=self.hidden_size, normalize=False, device=self.device) \n",
    "        self.GCN_2 = gnn.GCNConv(in_channels=self.hidden_size, out_channels=self.encoding_size, normalize=False, device=self.device)\n",
    "\n",
    "        # activations \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encoder(self, X): \n",
    "        X_hat = self.GCN_1(X, self.edge_index) # first layer: lower dimension feature matrix \n",
    "        X_hat = self.relu(X_hat)\n",
    "        Z_mean = self.GCN_2(X_hat, self.edge_index) # second layer: mean matrix\n",
    "        Z_logstd = self.GCN_2(X_hat, self.edge_index) # second layer: natural log of squared standard deviation\n",
    "        Z_std = torch.sqrt(torch.exp(Z_logstd)) # calculate the standard deviation \n",
    "        Z = torch.normal(Z_mean, Z_std) # random sample from normal distribution with the calculated mean and std\n",
    "        return Z\n",
    "\n",
    "    def decoder(self, Z): \n",
    "        Y_inner = torch.mm(Z.T, Z) # calculate inner product of matrix \n",
    "        Y_inner = Y_inner.reshape((-1)) # flatten the tensor \n",
    "        Y = self.sigmoid(Y_inner) # apply activation \n",
    "        return Y\n",
    "\n",
    "    def forward(self, X): \n",
    "        Z = self.encoder(X)\n",
    "        output = self.decoder(Z)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "Create two 4-node graphs of your choice by hand on paper with node labels (but no attributes). Begin with a 2-hidden layer GCN with weight matrics initialized at 1. Calculate the feed-forward output of the graph by hand. Compare it to your results using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_nodes_from([1,2,3,4])\n",
    "graph.add_edges_from([(1,2), (2, 3), (1, 4), (4, 2), (3, 1)])\n",
    "nx.draw(graph, labels={i:i for i in range(1, 5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 2-hidden layer GCN-AE by hand. \n",
    "\n",
    "1. Adjacency Matrix \n",
    "    * Node 1 = [0, 1, 1, 1]\n",
    "    * Node 2 = [1, 0, 1, 1]\n",
    "    * Node 3 = [1, 1, 0, 0]\n",
    "    * Node 4 = [1, 1, 0, 0]\n",
    "$$ \n",
    "\\LARGE{A} = \\begin{pmatrix}\n",
    "            0 & 1 & 1 & 1 \\\\\n",
    "            1 & 0 & 1 & 1 \\\\\n",
    "            1 & 1 & 0 & 0 \\\\\n",
    "            1 & 1 & 0 & 0\n",
    "            \\end{pmatrix} \\\\\n",
    "\n",
    "\\text{ with self loop } = \\begin{pmatrix}\n",
    "            1 & 1 & 1 & 1 \\\\\n",
    "            1 & 1 & 1 & 1 \\\\\n",
    "            1 & 1 & 1 & 0 \\\\\n",
    "            1 & 1 & 0 & 1\n",
    "            \\end{pmatrix} \n",
    "$$ \n",
    "We want to normalize the adjacency matrix by multiplying $D^{-\\frac{1}{2}}$ on each sides: \n",
    "$$\n",
    "\\LARGE{D} = \\begin{pmatrix} \n",
    "            4 & 0 & 0 & 0 \\\\\n",
    "            0 & 4 & 0 & 0 \\\\\n",
    "            0 & 0 & 3 & 0 \\\\\n",
    "            0 & 0 & 0 & 3\n",
    "            \\end{pmatrix} \\\\\n",
    "\\LARGE{D}^{-\\frac{1}{2}} = \\begin{pmatrix} \n",
    "            \\frac{1}{\\sqrt{4}} & 0 & 0 & 0 \\\\\n",
    "            0 & \\frac{1}{\\sqrt{4}} & 0 & 0 \\\\\n",
    "            0 & 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\\n",
    "            0 & 0 & 0 & \\frac{1}{\\sqrt{3}}\n",
    "            \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\LARGE{\\hat{A}} = \\LARGE{D}^{-\\frac{1}{2}} \\LARGE{A} \\LARGE{D}^{-\\frac{1}{2}} \\\\\n",
    "    =   \\begin{pmatrix}\n",
    "        \\frac{1}{4} &  \\frac{1}{4} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} \\\\\n",
    "        \\frac{1}{4} &  \\frac{1}{4} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} \\\\\n",
    "        \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{3} & 0 \\\\\n",
    "        \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & 0 & \\frac{1}{3}\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. Feature Matrix\n",
    "    * We didn't specify any node feature, so this is going to be the identity matrix. \n",
    "\n",
    "3. First GCN layer (dim: 4 -> 2)\n",
    "    * Weight Matrix: $$\\LARGE{W_1} = \\begin{pmatrix}\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \n",
    "            \\end{pmatrix}$$\n",
    "    * Full Equation: $$ ReLU(\\hat{A}XW) = ReLU(\n",
    "            \\begin{pmatrix}\n",
    "            \\frac{1}{4} &  \\frac{1}{4} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} \\\\\n",
    "            \\frac{1}{4} &  \\frac{1}{4} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} \\\\\n",
    "            \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{3} & 0 \\\\\n",
    "            \\frac{1}{\\sqrt{3}\\sqrt{4}} & \\frac{1}{\\sqrt{3}\\sqrt{4}} & 0 & \\frac{1}{3}\n",
    "            \\end{pmatrix} \\LARGE{X}\n",
    "            \\begin{pmatrix}\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \\\\\n",
    "            1 & 1 \n",
    "            \\end{pmatrix})$$\n",
    "    * Each node's representation after passing through this layer: \n",
    "        1. [1.07735027, 1.07735027]\n",
    "        2. [1.07735027, 1.07735027]\n",
    "        3. [0.9106836 , 0.9106836]\n",
    "        4. [0.9106836 , 0.9106836]\n",
    "\n",
    "4. Second GCN layer (dim: 2 -> 1)\n",
    "    * Weight Matrix: $$\\LARGE{W_2} = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            1 \n",
    "            \\end{pmatrix}$$\n",
    "    * Each node's representation after passing through this layer: \n",
    "        1. [2.12891712]\n",
    "        2. [2.12891712] \n",
    "        3. [1.85113934]\n",
    "        4. [1.85113934]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1289],\n",
       "        [2.1289],\n",
       "        [1.8511],\n",
       "        [1.8511]], device='mps:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the encoding in a 2 layer GCN \n",
    "edge_index = torch.tensor(list(graph.to_directed().edges)).T-1\n",
    "\n",
    "layer1 = GCNConvCustom(edge_index=edge_index, input_dim=4, output_dim=2, random_init=False, with_bias=False)\n",
    "output1 = layer1(torch.eye(4).to('mps'))\n",
    "layer2 = GCNConvCustom(edge_index=edge_index, input_dim=2, output_dim=1, random_init=False, with_bias=False)\n",
    "layer2(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "Link Prediction with GCN-AE\n",
    "\n",
    "Questions: \n",
    "* What is the loss function for the autoencoder and why is the setup appropriate for link-prediction? \n",
    "    - The idea of using a graph autoencoder for link prediction is to randomly take out part of the graph, and use the remaining portion of the graph to predict the removed portion of the graph. \n",
    "    - This process is similar to the encoding-decoding procedure of an autoencoder. The encoding is the model extracting information form the training portion of the graph. The decoding is the model reconstructing the connection of the test portion of the graph. \n",
    "    - The loss function of the autoencoder calculates the reconstruction loss, i.e. how different the reconstruction of the decoder is from the ground truth. One common approach is to use the MSE between the decoded tensor and the ground truth. \n",
    "\n",
    "* What if you wanted to take node attributes into account as well? \n",
    "    - For GCNs, the node attributes can just be passed into it as part of the encoding features, so there shouldn't be a difference in the procedure from the procedure without the node attributes. \n",
    "\n",
    "* How might you change the loss function?\n",
    "    - Although link prediction problem can be understood as a reconstruct problem, it is also a classification problem. For each pair of nodes, there can only be two possibilities, link or no link. This indicates that we can use binary cross-entropy as the loss function, instead of mean square error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation \n",
    "\"\"\"\n",
    "Strategy: \n",
    "* Randomly sample 50% edges (training), 20% edges (validation), and 30% edges (testing). \n",
    "* We want to evaluate against the edges that are uniformly distributed connected to each nodes, \n",
    "    so create a couple of random sampled train, validation, test datasets, evaluate the performance against each. \n",
    "\"\"\"\n",
    "def extract_train_test_data(edge_index, node_features=None, labels=None, num_of_trials=3): \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        edge_index: torch.Tensor, shape should be (2, # of edges in graph)\n",
    "        node_features: troch.Tensor, shape should be (# of nodes, feature dimension)\n",
    "        labels: torch.Tensor, shape should eb (# of nodes, )\n",
    "        \n",
    "    Return\n",
    "        datasets: list, contain randomly sampled (train_matrix, validation_matrix, test_matix) dataset; same length as the number of trials specified. \n",
    "            train_matrix: sub-graph created by sampling 50% of the edges from the original graph \n",
    "            validation_matix: sub-graph created by sampling 20% of the edges from the original graph \n",
    "            test_matrix: sub-graph of the rest of the 30% of the original graph\n",
    "    \"\"\"\n",
    "    num_edges = edge_index.shape[1] \n",
    "    train_size, val_size = int(0.5*num_edges), int(0.2*num_edges)\n",
    "    test_size = num_edges - train_size - val_size\n",
    "    print(f\"\"\"\n",
    "            There are a total of {num_edges}. \\n\n",
    "            Train dataset has {train_size} edges. \\n\n",
    "            Validation dataset has {val_size} edges. \\n\n",
    "            Test dataset has {test_size} edges. \n",
    "          \"\"\")\n",
    "    train_matrix, validation_matix, test_matrix = torch.utils.data.random_split(\n",
    "        edge_list, (train_size, valid_size, test_size)\n",
    "    )\n",
    "    return train_matrix, validation_matix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN_AE(edge_index=, input_size=, hidden_size_1=, hidden_size_2=, encoding_size=, output_size=, device='mps')\n",
    "criterions = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ee9abc2f8ed4c2bec59380a88532f6c4409e3142704504d9be0d180fda6aa0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
