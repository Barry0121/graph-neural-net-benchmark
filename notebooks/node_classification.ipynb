{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import torch \n",
    "import torch_geometric as torch_geo \n",
    "from torch_geometric.datasets import Planetoid, SNAPDataset\n",
    "from torch_geometric.transforms import NormalizeFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Node Classification Tasks</b>\n",
    "\n",
    "\n",
    "#### Approach each of the following classification tasks using the following methods:\n",
    "\n",
    "* classify nodes using only node features via FCN (use no graph information).\n",
    "* classify nodes using both node features and ad-hoc graph variables for each node (e.g. for a given node use degree, centrality measures, sum of words of the neighbors, etc as features).\n",
    "    * note: this is really the baseline to which one should compare e.g. GCN, n2v.\n",
    "* classify nodes using only graph structure via node2vec (donâ€™t use features for nodes).\n",
    "* classify nodes using both graph structure and node features by concatenating node2vec embeddings and node features.\n",
    "* classify nodes using GCN (using both node features and graph structure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "1. Explore different architectures and hyperparameters. \n",
    "2. Compare these models for each classification problem, using standard metrics (accuracy, precision, recall) and a thoughtful data analysis (e.g. are false positives more often high degree nodes?). \n",
    "    - For node2vec and GCN, plot the dense vector embeddings and try to interpret them (e.g. use tSNE to plot the embeddings, colored by label or node degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side Note: Testing on different types of graph\n",
    "Your classification problems should always be tested in circumstances similar to how the algorithm be used! Graph problems will either be:\n",
    "1. Transductive, when the graph structure is fixed ahead of time, but the labels remain unknown. \n",
    "    * e.g. given a fixed set of publications, can you classify them for an analysis?\n",
    "2. Inductive, when the graph evolves/changes post-training.\n",
    "    * e.g. a publisher has a service: when an author uploads their paper, the algorithm recommends a category/tag for labeling the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Datasets\n",
    "1. CORA: building off of last week's material \n",
    "    * Tip: start writing library functions automating portions for the next task.\n",
    "\n",
    "2. Choose another dataset from SNAP for node classification \n",
    "    * Describe a real world situation where this node classification would be useful (is it inductive or transductive?).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset#1: CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads Cora dataset, at root location: ../data/raw/Planetoid\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# data loading function for CORA\n",
    "def loader_cora_torch(filepath=\"../data/raw/Planetoid\", transform=None, batch_size=1, shuffle=False):\n",
    "    \"\"\"Return the CORA dataset\"\"\"\n",
    "    dataset = Planetoid(root=filepath, name='Cora', split='public', num_train_per_class=20, num_val=500, num_test=1000, transform=transform) # return a class of datasets\n",
    "    data = dataset[0]\n",
    "    # print some dataset statistics \n",
    "    print(f'Loads Cora dataset, at root location: {filepath}')\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "    print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "    # create adjacency matrix (for graph feature)\n",
    "    adj_mat = torch_geo.utils.to_dense_adj(data.edge_index) \n",
    "\n",
    "    return adj_mat[0], data.x, data.y\n",
    "\n",
    "\n",
    "graph_features, node_features, labels = loader_cora_torch() # load the cora dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 5.,  ..., 1., 4., 4.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset#2: SNAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SNAPDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIs undirected: \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mis_undirected()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m load_snap_torch()\n",
      "\u001b[1;32m/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb Cell 12\u001b[0m in \u001b[0;36mload_snap_torch\u001b[0;34m(filepath, transform)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_snap_torch\u001b[39m(filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data/raw/SNAPDataset\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m): \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     dataset \u001b[39m=\u001b[39m SNAPDataset(root\u001b[39m=\u001b[39mfilepath, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mego-twitter\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39mtransform)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     data \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/barryxue/Desktop/dsc180-graph-neural-net/notebooks/node_classification.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# print some dataset statistics \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SNAPDataset' is not defined"
     ]
    }
   ],
   "source": [
    "def load_snap_torch(filepath='../data/raw/SNAPDataset', transform=None): \n",
    "    dataset = SNAPDataset(root=filepath, name='ego-twitter', transform=transform)\n",
    "    data = dataset[0]\n",
    "    # print some dataset statistics \n",
    "    print(f'Loads Cora dataset, at root location: {filepath}')\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "    print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "    return data\n",
    "\n",
    "load_snap_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ee9abc2f8ed4c2bec59380a88532f6c4409e3142704504d9be0d180fda6aa0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
