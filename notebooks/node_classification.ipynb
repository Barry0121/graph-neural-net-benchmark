{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import torch \n",
    "import torch_geometric as torch_geo \n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Node Classification Tasks</b>\n",
    "\n",
    "\n",
    "#### Approach each of the following classification tasks using the following methods:\n",
    "\n",
    "* classify nodes using only node features via FCN (use no graph information).\n",
    "* classify nodes using both node features and ad-hoc graph variables for each node (e.g. for a given node use degree, centrality measures, sum of words of the neighbors, etc as features).\n",
    "* note: this is really the baseline to which one should compare e.g. GCN, n2v.\n",
    "* classify nodes using only graph structure via node2vec (donâ€™t use features for nodes).\n",
    "* classify nodes using both graph structure and node features by concatenating node2vec embeddings and node features.\n",
    "* classify nodes using GCN (using both node features and graph structure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "1. Explore different architectures and hyperparameters. \n",
    "2. Compare these models for each classification problem, using standard metrics (accuracy, precision, recall) and a thoughtful data analysis (e.g. are false positives more often high degree nodes?). \n",
    "    - For node2vec and GCN, plot the dense vector embeddings and try to interpret them (e.g. use tSNE to plot the embeddings, colored by label or node degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side Note: Testing on different types of graph\n",
    "Your classification problems should always be tested in circumstances similar to how the algorithm be used! Graph problems will either be:\n",
    "1. Transductive, when the graph structure is fixed ahead of time, but the labels remain unknown. \n",
    "    * e.g. given a fixed set of publications, can you classify them for an analysis?\n",
    "2. Inductive, when the graph evolves/changes post-training.\n",
    "    * e.g. a publisher has a service: when an author uploads their paper, the algorithm recommends a category/tag for labeling the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Datasets\n",
    "1. CORA: building off of last week's material \n",
    "    * Tip: start writing library functions automating portions for the next task.\n",
    "\n",
    "2. Choose another dataset from SNAP for node classification \n",
    "    * Describe a real world situation where this node classification would be useful (is it inductive or transductive?).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading function for CORA\n",
    "def load_cora_torch(filepath=\"../data/raw/Planetoid\"):\n",
    "    \"\"\"Return the CORA dataset\"\"\"\n",
    "    dataset = Planetoid(root=filepath, name='Cora', transform=NormalizeFeatures()) # return a class of datasets\n",
    "    data = dataset[0]\n",
    "    # print some dataset statistics \n",
    "    print(f'Loads Cora dataset, at root location: {filepath}')\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "    print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads Cora dataset, at root location: ../data/raw/Planetoid\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cora = load_cora_torch() # load the cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ee9abc2f8ed4c2bec59380a88532f6c4409e3142704504d9be0d180fda6aa0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
