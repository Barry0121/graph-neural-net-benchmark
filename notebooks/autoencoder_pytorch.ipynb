{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: [link](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1)\n",
    "\n",
    "### Autoencoder \n",
    "An autoencoder is a neural network that map features x to another representation of itself. In essen, the input features is passed into a encoder network and then the result is passed into a decoder network. This process: \n",
    "1. learns the data representation in lower-dimension space, i.e. a form of dimensionality reduction. \n",
    "2. <b>reconstruct</b> the original data based on the lower-dimension representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the encoder-decoder layers in one class\n",
    "class AE(nn.Module): \n",
    "    def __init__(self, **kwargs) -> None: # kwargs pass all arguments in the construction\n",
    "        \"\"\"\n",
    "        Constructor method, pass the configuration in as arguments\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder layers \n",
    "        self.encoder_hidden_layer = nn.Linear(in_features=kwargs[\"input_shape\"], out_features=128) # 1st hidden layer\n",
    "        self.encoder_output_layer = nn.Linear(in_features=128, out_features=128) # output layer \n",
    "\n",
    "        # decoder layers \n",
    "        self.decoder_hidden_layer = nn.Linear(in_features=128, out_features=128) # 1st hidden layer\n",
    "        self.decoder_output_layer = nn.Linear(in_features=128, out_features=kwargs[\"input_shape\"])\n",
    "\n",
    "    def forward(self, features): \n",
    "        \"\"\"\n",
    "        Forward pass function, called every time given a feature input \n",
    "        \"\"\"\n",
    "        # each layer has two passing, one for the layer and one for the activation\n",
    "        # pass input across the encoder layers \n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation) \n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        # pass output across the decoder layers\n",
    "        activation = self.decoder_hidden_layer(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gpu, initialize the model, optimizer, and loss function \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create model \n",
    "model = AE(input_shape=784).to(device)\n",
    "\n",
    "# create an optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# specify MSE\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use MNIST digits dataset from torchvision\n",
    "# transform the images to Tensor objects \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download the train, test datasets\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "\n",
    "# create train, test dataloader \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=128, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50, loss = 0.033165\n",
      "epoch : 2/50, loss = 0.018559\n",
      "epoch : 3/50, loss = 0.016618\n",
      "epoch : 4/50, loss = 0.015657\n",
      "epoch : 5/50, loss = 0.015069\n",
      "epoch : 6/50, loss = 0.014664\n",
      "epoch : 7/50, loss = 0.014351\n",
      "epoch : 8/50, loss = 0.014086\n",
      "epoch : 9/50, loss = 0.013868\n",
      "epoch : 10/50, loss = 0.013685\n",
      "epoch : 11/50, loss = 0.013271\n",
      "epoch : 12/50, loss = 0.012867\n",
      "epoch : 13/50, loss = 0.012696\n",
      "epoch : 14/50, loss = 0.012572\n",
      "epoch : 15/50, loss = 0.012486\n",
      "epoch : 16/50, loss = 0.012378\n",
      "epoch : 17/50, loss = 0.012308\n",
      "epoch : 18/50, loss = 0.012233\n",
      "epoch : 19/50, loss = 0.012163\n",
      "epoch : 20/50, loss = 0.012099\n",
      "epoch : 21/50, loss = 0.012049\n",
      "epoch : 22/50, loss = 0.011999\n",
      "epoch : 23/50, loss = 0.011950\n",
      "epoch : 24/50, loss = 0.011908\n",
      "epoch : 25/50, loss = 0.011870\n",
      "epoch : 26/50, loss = 0.011839\n",
      "epoch : 27/50, loss = 0.011795\n",
      "epoch : 28/50, loss = 0.011777\n",
      "epoch : 29/50, loss = 0.011742\n",
      "epoch : 30/50, loss = 0.011720\n",
      "epoch : 31/50, loss = 0.011692\n",
      "epoch : 32/50, loss = 0.011670\n",
      "epoch : 33/50, loss = 0.011648\n",
      "epoch : 34/50, loss = 0.011628\n",
      "epoch : 35/50, loss = 0.011607\n",
      "epoch : 36/50, loss = 0.011584\n",
      "epoch : 37/50, loss = 0.011573\n",
      "epoch : 38/50, loss = 0.011568\n",
      "epoch : 39/50, loss = 0.011548\n",
      "epoch : 40/50, loss = 0.011536\n",
      "epoch : 41/50, loss = 0.011532\n",
      "epoch : 42/50, loss = 0.011507\n",
      "epoch : 43/50, loss = 0.011500\n",
      "epoch : 44/50, loss = 0.011488\n",
      "epoch : 45/50, loss = 0.011481\n",
      "epoch : 46/50, loss = 0.011471\n",
      "epoch : 47/50, loss = 0.011464\n",
      "epoch : 48/50, loss = 0.011454\n",
      "epoch : 49/50, loss = 0.011444\n",
      "epoch : 50/50, loss = 0.011438\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "epochs = 50\n",
    "for epoch in range(epochs): \n",
    "    loss = 0 \n",
    "    for batch_features, _ in train_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # reset the gradients back to zero for each batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # compute accumulated gradients \n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients \n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss \n",
    "    loss /= len(train_loader)\n",
    "    # display the epoch training loss \n",
    "    print(f\"epoch : {epoch+1}/{epochs}, loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the first 10 \n",
    "image_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    ")\n",
    "images, labels = next(iter(image_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# get reconstruction of the same 10 images \n",
    "input_features = images.view(-1, 784).to(device)\n",
    "\n",
    "# turn off gradient descent (no training, only reconstruction)\n",
    "with torch.no_grad(): \n",
    "    output_features = model(input_features)\n",
    "reconstruction = output_features.reshape(10, 28, 28)\n",
    "reconstruction = reconstruction.cpu().numpy()\n",
    "print(reconstruction[0].shape)\n",
    "\n",
    "# translate the images to numpy array for plotting \n",
    "images = images.cpu().numpy()\n",
    "print(images[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the original vs the results \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "original_img, reconstruct_img = images[:, 0, :, :], reconstruction\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20,10)) # 2 rows 10 columns \n",
    "fig.set_facecolor('white')\n",
    "fig.suptitle(\"Top: Original, Bottom: Reconstructed with Epochs = 50\", fontsize=16, color='black')\n",
    "\n",
    "for i in range(10): \n",
    "    ax_original = axes[0, i]\n",
    "    ax_reconstruct = axes[1, i]\n",
    "\n",
    "    ax_original.imshow(original_img[i], cmap='gray')\n",
    "    ax_reconstruct.imshow(reconstruct_img[i], cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the original Autoencoder setup with 1 hidden layer is 3.6000256603583694\n"
     ]
    }
   ],
   "source": [
    "# evaluate the testing MSE of the original autoencoder \n",
    "loss = 0\n",
    "with torch.no_grad(): \n",
    "    for batch_features, _ in test_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        test_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += test_loss.item()\n",
    "        \n",
    "print(f\"The MSE of the original Autoencoder setup with 1 hidden layer is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try adding another hidden layer for both encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the number of hidden layers by 1, now we have 2 hidden layers in total\n",
    "class AE_v2(nn.Module): \n",
    "    def __init__(self, **kwargs) -> None: # kwargs pass all arguments in the construction\n",
    "        \"\"\"\n",
    "        Constructor method, pass the configuration in as arguments\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder layers \n",
    "        self.encoder_hidden_layer_1 = nn.Linear(in_features=kwargs[\"input_shape\"], out_features=256) # 1st hidden layer\n",
    "        self.encoder_hidden_layer_2 = nn.Linear(in_features=256, out_features=128) # 2nd hidden layer\n",
    "        self.encoder_output_layer = nn.Linear(in_features=128, out_features=128) # output layer \n",
    "\n",
    "        # decoder layers \n",
    "        self.decoder_hidden_layer_1 = nn.Linear(in_features=128, out_features=128) # 1st hidden layer\n",
    "        self.decoder_hidden_layer_2 = nn.Linear(in_features=128, out_features=256) # 2nd hidden layer\n",
    "        self.decoder_output_layer = nn.Linear(in_features=256, out_features=kwargs[\"input_shape\"])\n",
    "\n",
    "    def forward(self, features): \n",
    "        \"\"\"\n",
    "        Forward pass function, called every time given a feature input \n",
    "        \"\"\"\n",
    "        # each layer has two passing, one for the layer and one for the activation\n",
    "        # pass input across the encoder layers \n",
    "        activation = self.encoder_hidden_layer_1(features)\n",
    "        activation = torch.relu(activation) \n",
    "        activation = self.encoder_hidden_layer_2(activation)\n",
    "        activation = torch.relu(activation) \n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "\n",
    "        # pass output across the decoder layers\n",
    "        activation = self.decoder_hidden_layer_1(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_hidden_layer_2(activation)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gpu, initialize the model, optimizer, and loss function \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create model \n",
    "model = AE_v2(input_shape=784).to(device)\n",
    "\n",
    "# create an optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# specify MSE\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use MNIST digits dataset from torchvision\n",
    "# transform the images to Tensor objects \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download the train, test datasets\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "\n",
    "# create train, test dataloader \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=128, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50, loss = 0.041231\n",
      "epoch : 2/50, loss = 0.022489\n",
      "epoch : 3/50, loss = 0.018806\n",
      "epoch : 4/50, loss = 0.017085\n",
      "epoch : 5/50, loss = 0.016056\n",
      "epoch : 6/50, loss = 0.015251\n",
      "epoch : 7/50, loss = 0.014643\n",
      "epoch : 8/50, loss = 0.014172\n",
      "epoch : 9/50, loss = 0.013811\n",
      "epoch : 10/50, loss = 0.013498\n",
      "epoch : 11/50, loss = 0.013252\n",
      "epoch : 12/50, loss = 0.013010\n",
      "epoch : 13/50, loss = 0.012828\n",
      "epoch : 14/50, loss = 0.012647\n",
      "epoch : 15/50, loss = 0.012516\n",
      "epoch : 16/50, loss = 0.012365\n",
      "epoch : 17/50, loss = 0.012241\n",
      "epoch : 18/50, loss = 0.012113\n",
      "epoch : 19/50, loss = 0.011997\n",
      "epoch : 20/50, loss = 0.011915\n",
      "epoch : 21/50, loss = 0.011790\n",
      "epoch : 22/50, loss = 0.011706\n",
      "epoch : 23/50, loss = 0.011637\n",
      "epoch : 24/50, loss = 0.011557\n",
      "epoch : 25/50, loss = 0.011484\n",
      "epoch : 26/50, loss = 0.011446\n",
      "epoch : 27/50, loss = 0.011371\n",
      "epoch : 28/50, loss = 0.011327\n",
      "epoch : 29/50, loss = 0.011286\n",
      "epoch : 30/50, loss = 0.011229\n",
      "epoch : 31/50, loss = 0.011209\n",
      "epoch : 32/50, loss = 0.011165\n",
      "epoch : 33/50, loss = 0.011124\n",
      "epoch : 34/50, loss = 0.011089\n",
      "epoch : 35/50, loss = 0.011053\n",
      "epoch : 36/50, loss = 0.011006\n",
      "epoch : 37/50, loss = 0.010998\n",
      "epoch : 38/50, loss = 0.010948\n",
      "epoch : 39/50, loss = 0.010918\n",
      "epoch : 40/50, loss = 0.010886\n",
      "epoch : 41/50, loss = 0.010865\n",
      "epoch : 42/50, loss = 0.010840\n",
      "epoch : 43/50, loss = 0.010805\n",
      "epoch : 44/50, loss = 0.010773\n",
      "epoch : 45/50, loss = 0.010763\n",
      "epoch : 46/50, loss = 0.010723\n",
      "epoch : 47/50, loss = 0.010707\n",
      "epoch : 48/50, loss = 0.010690\n",
      "epoch : 49/50, loss = 0.010656\n",
      "epoch : 50/50, loss = 0.010638\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "epochs = 50\n",
    "for epoch in range(epochs): \n",
    "    loss = 0 \n",
    "    for batch_features, _ in train_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # reset the gradients back to zero for each batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # compute accumulated gradients \n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients \n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss \n",
    "    loss /= len(train_loader)\n",
    "    # display the epoch training loss \n",
    "    print(f\"epoch : {epoch+1}/{epochs}, loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the new Autoencoder setup with 2 hidden layers is 3.306469895876944\n"
     ]
    }
   ],
   "source": [
    "# evaluate the testing MSE of the new autoencoder with an extra layer\n",
    "loss = 0\n",
    "with torch.no_grad(): \n",
    "    for batch_features, _ in test_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        test_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += test_loss.item()\n",
    "        \n",
    "print(f\"The MSE of the new Autoencoder setup with 2 hidden layers is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try decrease the final dimension for the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the final encoding dimension \n",
    "class AE_v3(nn.Module): \n",
    "    def __init__(self, **kwargs) -> None: # kwargs pass all arguments in the construction\n",
    "        \"\"\"\n",
    "        Constructor method, pass the configuration in as arguments\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder layers \n",
    "        self.encoder_hidden_layer_1 = nn.Linear(in_features=kwargs[\"input_shape\"], out_features=128) # 1st hidden layer\n",
    "        self.encoder_hidden_layer_2 = nn.Linear(in_features=128, out_features=64) # 2nd hidden layer\n",
    "        self.encoder_output_layer = nn.Linear(in_features=64, out_features=64) # output layer \n",
    "\n",
    "        # decoder layers \n",
    "        self.decoder_hidden_layer_1 = nn.Linear(in_features=64, out_features=64) # 1st hidden layer\n",
    "        self.decoder_hidden_layer_2 = nn.Linear(in_features=64, out_features=128) # 2nd hidden layer\n",
    "        self.decoder_output_layer = nn.Linear(in_features=128, out_features=kwargs[\"input_shape\"])\n",
    "\n",
    "    def forward(self, features): \n",
    "        \"\"\"\n",
    "        Forward pass function, called every time given a feature input \n",
    "        \"\"\"\n",
    "        # each layer has two passing, one for the layer and one for the activation\n",
    "        # pass input across the encoder layers \n",
    "        activation = self.encoder_hidden_layer_1(features)\n",
    "        activation = torch.relu(activation) \n",
    "        activation = self.encoder_hidden_layer_2(activation)\n",
    "        activation = torch.relu(activation) \n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "\n",
    "        # pass output across the decoder layers\n",
    "        activation = self.decoder_hidden_layer_1(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_hidden_layer_2(activation)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gpu, initialize the model, optimizer, and loss function \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create model \n",
    "model = AE_v3(input_shape=784).to(device)\n",
    "\n",
    "# create an optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# specify MSE\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use MNIST digits dataset from torchvision\n",
    "# transform the images to Tensor objects \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download the train, test datasets\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data/raw/torch_datasets', \n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True, \n",
    ") \n",
    "\n",
    "# create train, test dataloader \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=128, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50, loss = 0.047063\n",
      "epoch : 2/50, loss = 0.026183\n",
      "epoch : 3/50, loss = 0.022053\n",
      "epoch : 4/50, loss = 0.020127\n",
      "epoch : 5/50, loss = 0.019006\n",
      "epoch : 6/50, loss = 0.018189\n",
      "epoch : 7/50, loss = 0.017432\n",
      "epoch : 8/50, loss = 0.016779\n",
      "epoch : 9/50, loss = 0.016270\n",
      "epoch : 10/50, loss = 0.015748\n",
      "epoch : 11/50, loss = 0.015363\n",
      "epoch : 12/50, loss = 0.015065\n",
      "epoch : 13/50, loss = 0.014824\n",
      "epoch : 14/50, loss = 0.014581\n",
      "epoch : 15/50, loss = 0.014358\n",
      "epoch : 16/50, loss = 0.014140\n",
      "epoch : 17/50, loss = 0.013986\n",
      "epoch : 18/50, loss = 0.013783\n",
      "epoch : 19/50, loss = 0.013623\n",
      "epoch : 20/50, loss = 0.013485\n",
      "epoch : 21/50, loss = 0.013333\n",
      "epoch : 22/50, loss = 0.013211\n",
      "epoch : 23/50, loss = 0.013119\n",
      "epoch : 24/50, loss = 0.013019\n",
      "epoch : 25/50, loss = 0.012947\n",
      "epoch : 26/50, loss = 0.012874\n",
      "epoch : 27/50, loss = 0.012802\n",
      "epoch : 28/50, loss = 0.012728\n",
      "epoch : 29/50, loss = 0.012664\n",
      "epoch : 30/50, loss = 0.012601\n",
      "epoch : 31/50, loss = 0.012576\n",
      "epoch : 32/50, loss = 0.012490\n",
      "epoch : 33/50, loss = 0.012440\n",
      "epoch : 34/50, loss = 0.012376\n",
      "epoch : 35/50, loss = 0.012311\n",
      "epoch : 36/50, loss = 0.012263\n",
      "epoch : 37/50, loss = 0.012207\n",
      "epoch : 38/50, loss = 0.012159\n",
      "epoch : 39/50, loss = 0.012115\n",
      "epoch : 40/50, loss = 0.012045\n",
      "epoch : 41/50, loss = 0.012001\n",
      "epoch : 42/50, loss = 0.011979\n",
      "epoch : 43/50, loss = 0.011946\n",
      "epoch : 44/50, loss = 0.011907\n",
      "epoch : 45/50, loss = 0.011881\n",
      "epoch : 46/50, loss = 0.011839\n",
      "epoch : 47/50, loss = 0.011809\n",
      "epoch : 48/50, loss = 0.011772\n",
      "epoch : 49/50, loss = 0.011736\n",
      "epoch : 50/50, loss = 0.011701\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "epochs = 50\n",
    "for epoch in range(epochs): \n",
    "    loss = 0 \n",
    "    for batch_features, _ in train_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # reset the gradients back to zero for each batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # compute accumulated gradients \n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients \n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss \n",
    "    loss /= len(train_loader)\n",
    "    # display the epoch training loss \n",
    "    print(f\"epoch : {epoch+1}/{epochs}, loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the new Autoencoder setup with 2 hidden layers and lower final encoding dimension is 3.6505118454806507\n"
     ]
    }
   ],
   "source": [
    "# evaluate the testing MSE of the new autoencoder with an extra layer\n",
    "loss = 0\n",
    "with torch.no_grad(): \n",
    "    for batch_features, _ in test_loader: \n",
    "        # reshape batch data [N, 784] (flatten it) and load it to the device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # compute reconstruction with model \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss (MSE)\n",
    "        test_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss \n",
    "        loss += test_loss.item()\n",
    "        \n",
    "print(f\"The MSE of the new Autoencoder setup with 2 hidden layers and lower final encoding dimension is {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ee9abc2f8ed4c2bec59380a88532f6c4409e3142704504d9be0d180fda6aa0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
